"""
äº¤äº’å¼äººä½“å§¿æ€è°ƒèŠ‚å™¨
åŸºäºFlask + pyrenderå®ç°Webç«¯SMPLXå§¿æ€è°ƒèŠ‚
"""

import base64
import io
import json
import math
from datetime import datetime
from pathlib import Path
from typing import Tuple

import numpy as np
import pyrender
import torch
import trimesh
from PIL import Image
from flask import Flask, request, jsonify, render_template
from smplx import SMPLX

# ==================== é…ç½®å¸¸é‡ ====================
# æ•°æ®é›†æ–‡ä»¶ï¼šåŒ…å«äººä½“åŠ¨ä½œåºåˆ—çš„å§¿æ€å‚æ•°
# è¦æ±‚ï¼šNPZæ ¼å¼ï¼ŒåŒ…å«poses[T,156]å’Œbetas[10]æ•°ç»„
# T=å¸§æ•°ï¼Œ156=SMPLXå‚æ•°ç»´åº¦ï¼ˆglobal_orient+body_pose+hand_posesï¼‰
DATA_SET: Path = Path(r'./datasets/AMASS/G18 push kick right poses.npz')

# SMPLXäººä½“æ¨¡å‹æ–‡ä»¶ï¼šå®šä¹‰äººä½“ç½‘æ ¼æ‹“æ‰‘å’Œè’™çš®æƒé‡
# æ”¯æŒï¼šMALE/FEMALE/NEUTRALï¼Œå½±å“ä½“å‹å’Œæ¯”ä¾‹
SMPL_MODEL: Path = Path(r'./models/smplx/SMPLX_MALE.npz')

# æ¸²æŸ“é…ç½®ï¼šå•å¸§å›¾åƒåˆ†è¾¨ç‡
# åºåˆ—å›¾åƒæ€»å®½åº¦ = RENDER_WIDTH Ã— å¸§æ•°
RENDER_WIDTH = 1200
RENDER_HEIGHT = 1200

# åŠ è½½å…³èŠ‚é…ç½®
with open('./static/joint_config.json', 'r', encoding='utf-8') as f:
    joint_config_data = json.load(f)
    CORE_JOINTS = joint_config_data['core_joints']

# ==================== Flaskåº”ç”¨åˆå§‹åŒ– ====================
app = Flask(__name__)


class PoseAdjusterEngine:
    """
    å§¿æ€è°ƒèŠ‚å¼•æ“æ ¸å¿ƒç±»
    """

    def __init__(self, start_frame: int, frame_interval: int, num_frames: int, frame_offset: int = 0):
        self.poses = None
        self.betas = None
        self.model = None
        self.frame_indices = []
        self.current_frame_idx = 0

        # åºåˆ—é…ç½®
        self.start_frame = start_frame
        self.frame_interval = frame_interval
        self.num_frames = num_frames
        self.frame_offset = frame_offset  # é¢„æµ‹æ•°æ®ç›¸å¯¹äºGTçš„åç§»å¸§æ•°

        # å½“å‰è°ƒèŠ‚çŠ¶æ€ï¼šå­˜å‚¨æ¯å¸§çš„å§¿æ€è°ƒèŠ‚
        self.adjusted_poses = {}  # {frame_idx: adjusted_pose_tensor}

        # ç›¸æœºçŠ¶æ€
        self.camera_pose = np.array([
            [0.6102284363588065, 0.22558472023756496, -0.7594292524352928, -1.8948403428657872],
            [-0.7864855217646244, 0.0573172953978972, -0.614943291452878, -1.4792258307646078],
            [-0.09519337956872702, 0.972535995037516, 0.2123957599451424, 0.40015489940524757],
            [0.0, 0.0, 0.0, 1.0],
        ])

        # æ•°æ®é›†ä¿¡æ¯
        self.total_frames = 0
        self.framerate = 30.0

        self.load_data()

    def load_data(self):
        """åŠ è½½æ•°æ®å’Œæ¨¡å‹"""
        print(f'ğŸ”„ åŠ è½½æ•°æ®é›†: {DATA_SET}')
        data = np.load(DATA_SET)
        self.poses = data['poses']
        self.betas = data['betas']

        # è·å–æ•°æ®é›†ä¿¡æ¯
        self.total_frames = self.poses.shape[0]
        try:
            self.framerate = float(data['mocap_framerate'])
        except KeyError:
            self.framerate = 30.0  # é»˜è®¤å¸§ç‡

        # è®¡ç®—å¸§åºåˆ—
        self.frame_indices = [self.start_frame + i * self.frame_interval for i in range(self.num_frames)]
        print(f'ğŸ¯ é€‰æ‹©å¸§åºåˆ—: {self.frame_indices}')

        # åŠ è½½SMPLXæ¨¡å‹
        print('ğŸ”„ åŠ è½½SMPLXæ¨¡å‹...')
        self.model = SMPLX(
            model_path=SMPL_MODEL.as_posix(),
            gender="male",
            num_betas=10,
            use_pca=False,
            flat_hand_mean=True
        )
        print('âœ… æ¨¡å‹åŠ è½½å®Œæˆ')

    def get_current_poses(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        è·å–å½“å‰å¸§çš„GTå’Œè°ƒèŠ‚åçš„å§¿æ€ï¼ˆè€ƒè™‘å¸§åç§»ï¼‰
        
        :return: (gt_pose, adjusted_pose)
        """
        frame_idx = self.frame_indices[self.current_frame_idx]

        # GTå§¿æ€ï¼ˆå§‹ç»ˆä½¿ç”¨åŸå§‹å¸§ï¼‰
        gt_pose = torch.tensor(self.poses[frame_idx:frame_idx + 1], dtype=torch.float32)

        # é¢„æµ‹å§¿æ€çš„åŸºç¡€å¸§ï¼ˆè€ƒè™‘åç§»ï¼‰
        predicted_base_frame = frame_idx + self.frame_offset

        # ç¡®ä¿åç§»åçš„å¸§ä¸è¶…å‡ºæ•°æ®èŒƒå›´
        if predicted_base_frame < 0 or predicted_base_frame >= self.total_frames:
            # å¦‚æœåç§»è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨åŸå§‹å¸§ä½œä¸ºåŸºç¡€
            predicted_base_frame = frame_idx

        # é¢„æµ‹å§¿æ€å§‹ç»ˆä»åç§»åçš„åŸºç¡€å¸§å¼€å§‹
        predicted_pose = torch.tensor(self.poses[predicted_base_frame:predicted_base_frame + 1], dtype=torch.float32)

        # å¦‚æœå½“å‰å¸§æœ‰ç”¨æˆ·è°ƒèŠ‚ï¼Œè¿™äº›è°ƒèŠ‚åº”è¯¥æ˜¯å­˜å‚¨ä¸ºç›¸å¯¹äºGTçš„ä¿®æ”¹
        # æˆ‘ä»¬éœ€è¦å°†è¿™äº›ä¿®æ”¹åº”ç”¨åˆ°é¢„æµ‹åŸºç¡€å§¿æ€ä¸Š
        if self.current_frame_idx in self.adjusted_poses:
            # è·å–ç”¨æˆ·çš„è°ƒèŠ‚æ•°æ®ï¼ˆè¿™åº”è¯¥æ˜¯ç»å¯¹è§’åº¦ï¼‰
            user_adjusted_pose = self.adjusted_poses[self.current_frame_idx].clone()

            # ç›´æ¥ä½¿ç”¨ç”¨æˆ·è°ƒèŠ‚çš„ç»å¯¹è§’åº¦ä½œä¸ºæœ€ç»ˆé¢„æµ‹å§¿æ€
            # ï¼ˆè¿™é‡Œå‡è®¾ç”¨æˆ·è°ƒèŠ‚æ˜¯æƒ³è¦çš„æœ€ç»ˆè§’åº¦ï¼‰
            predicted_pose = user_adjusted_pose

        return gt_pose, predicted_pose

    def adjust_joint(self, joint_name: str, axis: int, angle_degrees: float, operation: str = 'set'):
        """
        è°ƒèŠ‚æŒ‡å®šå…³èŠ‚çš„è§’åº¦ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥æ“ä½œç»å¯¹è§’åº¦
        
        :param joint_name: å…³èŠ‚åç§°
        :param axis: è½´å‘ç´¢å¼• (0, 1, 2)
        :param angle_degrees: ç»å¯¹è§’åº¦å€¼ï¼ˆåº¦æ•°ï¼‰
        :param operation: æ“ä½œç±»å‹ ('set', 'add', 'reset')
        """
        if joint_name not in CORE_JOINTS:
            raise ValueError(f'ä¸æ”¯æŒçš„å…³èŠ‚: {joint_name}')

        joint_config = CORE_JOINTS[joint_name]
        if axis < 0 or axis >= len(joint_config['indices']):
            raise ValueError(f'æ— æ•ˆçš„è½´å‘ç´¢å¼•: {axis}')

        # è·å–å½“å‰å§¿æ€
        gt_pose, current_adjusted = self.get_current_poses()

        # è·å–å§¿æ€ç´¢å¼•
        pose_index = joint_config['indices'][axis]
        angle_radians = math.radians(angle_degrees)

        if operation == 'set':
            # ç›´æ¥è®¾ç½®ç»å¯¹è§’åº¦
            current_adjusted[0, pose_index] = angle_radians
        elif operation == 'add':
            # å¢é‡è°ƒèŠ‚
            current_adjusted[0, pose_index] += angle_radians
        elif operation == 'reset':
            # é‡ç½®åˆ°åç§»åçš„åŸºç¡€å§¿æ€
            frame_idx = self.frame_indices[self.current_frame_idx]
            reset_base_frame = frame_idx + self.frame_offset

            # ç¡®ä¿åç§»åçš„å¸§ä¸è¶…å‡ºæ•°æ®èŒƒå›´
            if reset_base_frame < 0 or reset_base_frame >= self.total_frames:
                reset_base_frame = frame_idx

            reset_base_pose = torch.tensor(self.poses[reset_base_frame:reset_base_frame + 1], dtype=torch.float32)
            current_adjusted[0, pose_index] = reset_base_pose[0, pose_index]

        # ä¿å­˜è°ƒèŠ‚ç»“æœ
        self.adjusted_poses[self.current_frame_idx] = current_adjusted

    def copy_prev_frame_adjustments(self):
        """
        å¤åˆ¶ä¸Šä¸€å¸§çš„è°ƒèŠ‚å˜åŒ–é‡åˆ°å½“å‰å¸§
        è®¡ç®—ä¸Šä¸€å¸§é¢„æµ‹ç›¸å¯¹äºGTçš„å·®å¼‚ï¼Œç„¶ååº”ç”¨åˆ°å½“å‰å¸§çš„GTä¸Š
        """
        if self.current_frame_idx == 0:
            return False  # ç¬¬ä¸€å¸§æ²¡æœ‰ä¸Šä¸€å¸§

        prev_frame_idx = self.current_frame_idx - 1
        if prev_frame_idx in self.adjusted_poses:
            # è·å–ä¸Šä¸€å¸§çš„GTå§¿æ€
            prev_actual_frame = self.frame_indices[prev_frame_idx]
            prev_gt_pose = torch.tensor(self.poses[prev_actual_frame:prev_actual_frame + 1], dtype=torch.float32)

            # è·å–ä¸Šä¸€å¸§çš„è°ƒèŠ‚åå§¿æ€
            prev_adjusted_pose = self.adjusted_poses[prev_frame_idx]

            # è®¡ç®—è°ƒèŠ‚å˜åŒ–é‡ï¼ˆç›¸å¯¹è°ƒèŠ‚é‡ï¼‰
            adjustment_delta = prev_adjusted_pose - prev_gt_pose

            # è·å–å½“å‰å¸§çš„GTå§¿æ€
            current_actual_frame = self.frame_indices[self.current_frame_idx]
            current_gt_pose = torch.tensor(self.poses[current_actual_frame:current_actual_frame + 1],
                                           dtype=torch.float32)

            # å°†è°ƒèŠ‚å˜åŒ–é‡åº”ç”¨åˆ°å½“å‰å¸§GTä¸Š
            current_adjusted_pose = current_gt_pose + adjustment_delta

            # ä¿å­˜åˆ°å½“å‰å¸§
            self.adjusted_poses[self.current_frame_idx] = current_adjusted_pose
            return True
        return False

    def create_body_mesh(self, pose: torch.Tensor, material: pyrender.Material) -> pyrender.Mesh:
        """
        åˆ›å»ºäººä½“3Dç½‘æ ¼
        
        :param pose: å§¿æ€å‚æ•°
        :param material: æ¸²æŸ“æè´¨
        :return: pyrender.Meshå¯¹è±¡
        """
        betas_tensor = torch.tensor(self.betas[:10][None], dtype=torch.float32)
        transl = torch.zeros(1, 3)

        output = self.model(
            betas=betas_tensor,
            global_orient=pose[:, :3],
            body_pose=pose[:, 3:66],
            left_hand_pose=pose[:, 66:111],
            right_hand_pose=pose[:, 111:],
            transl=transl
        )
        vertices = output.vertices.detach().cpu().numpy().squeeze()
        body_mesh = trimesh.Trimesh(vertices, self.model.faces)
        return pyrender.Mesh.from_trimesh(body_mesh, material=material, smooth=False)

    def render_single_frame(self, frame_idx: int) -> np.ndarray:
        """
        æ¸²æŸ“å•å¸§åŒå±‚æ¨¡å‹ï¼ˆGT + é¢„æµ‹åç§»åï¼‰
        
        :param frame_idx: å¸§ç´¢å¼•
        :return: æ¸²æŸ“çš„å›¾åƒæ•°ç»„
        """
        # ä¸´æ—¶åˆ‡æ¢åˆ°æŒ‡å®šå¸§æ¥è·å–æ­£ç¡®çš„å§¿æ€
        original_frame_idx = self.current_frame_idx
        self.current_frame_idx = frame_idx

        # ä½¿ç”¨get_current_posesæ–¹æ³•è·å–æ­£ç¡®çš„GTå’Œé¢„æµ‹å§¿æ€ï¼ˆåŒ…å«åç§»ï¼‰
        gt_pose, predicted_pose = self.get_current_poses()

        # æ¢å¤åŸå§‹å¸§ç´¢å¼•
        self.current_frame_idx = original_frame_idx

        # åˆ›å»ºæè´¨
        gt_material = pyrender.MetallicRoughnessMaterial(
            metallicFactor=0.2,
            roughnessFactor=0.6,
            alphaMode='OPAQUE',
            baseColorFactor=(74 / 255, 84 / 255, 153 / 255, 0.7)  # è“è‰²ï¼ŒåŠé€æ˜
        )

        pred_material = pyrender.MetallicRoughnessMaterial(
            metallicFactor=0.2,
            roughnessFactor=0.6,
            alphaMode='OPAQUE',
            baseColorFactor=(153 / 255, 84 / 255, 74 / 255, 0.8)  # æ£•è‰²ï¼ŒåŠé€æ˜
        )

        # åˆ›å»ºç½‘æ ¼
        gt_mesh = self.create_body_mesh(gt_pose, gt_material)
        pred_mesh = self.create_body_mesh(predicted_pose, pred_material)

        # åˆ›å»ºåœºæ™¯
        scene = pyrender.Scene(ambient_light=[0.3, 0.3, 0.3], bg_color=[1.0, 1.0, 1.0, 1.0])

        # æ·»åŠ ç½‘æ ¼
        scene.add(gt_mesh)
        scene.add(pred_mesh)

        # æ·»åŠ å…‰æº
        directional_light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=3.0)
        light_pose = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 3], [0, 0, 0, 1]])
        scene.add(directional_light, pose=light_pose)

        fill_light = pyrender.DirectionalLight(color=[0.8, 0.8, 0.9], intensity=2.0)
        fill_light_pose = np.eye(4)
        fill_light_pose[:3, 3] = np.array([2, 1, 2])
        scene.add(fill_light, pose=fill_light_pose)

        # è®¾ç½®ç›¸æœº
        camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)
        scene.add(camera, pose=self.camera_pose)

        # æ¸²æŸ“
        renderer = pyrender.OffscreenRenderer(RENDER_WIDTH, RENDER_HEIGHT)
        color, _ = renderer.render(scene)
        renderer.delete()

        return color

    def render_sequence(self) -> str:
        """
        æ¸²æŸ“å¤šå¸§åºåˆ—ï¼ˆ1è¡ŒNUM_FRAMESåˆ—ï¼‰
        
        :return: Base64ç¼–ç çš„PNGå›¾åƒ
        """
        frames = []

        # æ¸²æŸ“æ¯ä¸€å¸§
        for i in range(self.num_frames):
            frame_image = self.render_single_frame(i)
            frames.append(frame_image)

        # æ°´å¹³æ‹¼æ¥æ‰€æœ‰å¸§
        sequence_width = RENDER_WIDTH * self.num_frames
        sequence_height = RENDER_HEIGHT
        sequence_image = np.zeros((sequence_height, sequence_width, 3), dtype=np.uint8)

        for i, frame in enumerate(frames):
            x_start = i * RENDER_WIDTH
            x_end = (i + 1) * RENDER_WIDTH
            sequence_image[:, x_start:x_end, :] = frame

        # åœ¨å½“å‰ç¼–è¾‘å¸§å‘¨å›´æ·»åŠ é«˜äº®è¾¹æ¡†
        current_x_start = self.current_frame_idx * RENDER_WIDTH
        current_x_end = (self.current_frame_idx + 1) * RENDER_WIDTH

        # ç»˜åˆ¶çº¢è‰²è¾¹æ¡†è¡¨ç¤ºå½“å‰ç¼–è¾‘å¸§
        border_width = 5
        sequence_image[:border_width, current_x_start:current_x_end, :] = [255, 0, 0]  # ä¸Šè¾¹æ¡†
        sequence_image[-border_width:, current_x_start:current_x_end, :] = [255, 0, 0]  # ä¸‹è¾¹æ¡†
        sequence_image[:, current_x_start:current_x_start + border_width, :] = [255, 0, 0]  # å·¦è¾¹æ¡†
        sequence_image[:, current_x_end - border_width:current_x_end, :] = [255, 0, 0]  # å³è¾¹æ¡†

        # è½¬æ¢ä¸ºBase64
        image = Image.fromarray(sequence_image)
        buffer = io.BytesIO()
        image.save(buffer, format='PNG')
        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

        return f'data:image/png;base64,{image_base64}'

    def render_sequence_for_export(self) -> str:
        """
        æ¸²æŸ“å¤šå¸§åºåˆ—ç”¨äºå¯¼å‡ºï¼ˆæ— è¾¹æ¡†æ ‡è¯†ï¼‰
        
        :return: Base64ç¼–ç çš„PNGå›¾åƒ
        """
        frames = []

        # æ¸²æŸ“æ¯ä¸€å¸§
        for i in range(self.num_frames):
            frame_image = self.render_single_frame(i)
            frames.append(frame_image)

        # æ°´å¹³æ‹¼æ¥æ‰€æœ‰å¸§ï¼ˆæ— è¾¹æ¡†ï¼‰
        sequence_width = RENDER_WIDTH * self.num_frames
        sequence_height = RENDER_HEIGHT
        sequence_image = np.zeros((sequence_height, sequence_width, 3), dtype=np.uint8)

        for i, frame in enumerate(frames):
            x_start = i * RENDER_WIDTH
            x_end = (i + 1) * RENDER_WIDTH
            sequence_image[:, x_start:x_end, :] = frame

        # è½¬æ¢ä¸ºBase64
        image = Image.fromarray(sequence_image)
        buffer = io.BytesIO()
        image.save(buffer, format='PNG')
        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

        return f'data:image/png;base64,{image_base64}'


# ==================== Flaskè·¯ç”± ====================

@app.route('/')
def index():
    """ä¸»é¡µé¢"""
    return render_template('pose_adjuster.html')


@app.route('/api/render')
def api_render():
    """æ¸²æŸ“åºåˆ—"""
    try:
        image_base64 = engine.render_sequence()

        # æ·»åŠ æ—¶é—´æˆ³é˜²æ­¢ç¼“å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]  # æ¯«ç§’çº§æ—¶é—´æˆ³

        return jsonify({
            'success': True,
            'image': image_base64,
            'frame_idx': engine.current_frame_idx,
            'frame_count': len(engine.frame_indices),
            'actual_frame': engine.frame_indices[engine.current_frame_idx],
            'modified': engine.current_frame_idx in engine.adjusted_poses,
            'timestamp': timestamp
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/adjust', methods=['POST'])
def api_adjust():
    """è°ƒèŠ‚å…³èŠ‚è§’åº¦"""
    try:
        data = request.json
        joint_name = data['joint_name']
        axis = int(data['axis'])
        angle = float(data['angle'])
        operation = data.get('operation', 'set')

        engine.adjust_joint(joint_name, axis, angle, operation)

        # é‡æ–°æ¸²æŸ“
        image_base64 = engine.render_sequence()

        return jsonify({
            'success': True,
            'image': image_base64,
            'modified': True
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/navigate', methods=['POST'])
def api_navigate():
    """å¸§å¯¼èˆª"""
    try:
        data = request.json
        direction = data['direction']  # 'prev', 'next', 'goto'

        if direction == 'prev':
            engine.current_frame_idx = max(0, engine.current_frame_idx - 1)
        elif direction == 'next':
            engine.current_frame_idx = min(len(engine.frame_indices) - 1, engine.current_frame_idx + 1)
        elif direction == 'goto':
            target_idx = int(data['target_idx'])
            engine.current_frame_idx = max(0, min(len(engine.frame_indices) - 1, target_idx))

        # é‡æ–°æ¸²æŸ“
        image_base64 = engine.render_sequence()

        return jsonify({
            'success': True,
            'image': image_base64,
            'frame_idx': engine.current_frame_idx,
            'frame_count': len(engine.frame_indices),
            'actual_frame': engine.frame_indices[engine.current_frame_idx],
            'modified': engine.current_frame_idx in engine.adjusted_poses
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/reset', methods=['POST'])
def api_reset():
    """é‡ç½®å½“å‰å¸§"""
    try:
        # ç§»é™¤å½“å‰å¸§çš„è°ƒèŠ‚
        if engine.current_frame_idx in engine.adjusted_poses:
            del engine.adjusted_poses[engine.current_frame_idx]

        # é‡æ–°æ¸²æŸ“
        image_base64 = engine.render_sequence()

        return jsonify({
            'success': True,
            'image': image_base64,
            'modified': False
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/export')
def api_export():
    """å¯¼å‡ºå½“å‰æ¸²æŸ“ç»“æœ"""
    try:
        image_base64 = engine.render_sequence_for_export()

        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºä¿å­˜åˆ°æ–‡ä»¶ç­‰
        return jsonify({
            'success': True,
            'image': image_base64,
            'filename': f'pose_adjustment_sequence_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/reset_joint', methods=['POST'])
def api_reset_joint():
    """é‡ç½®å•ä¸ªå…³èŠ‚"""
    try:
        data = request.json
        joint_name = data['joint_name']
        axis = int(data['axis'])

        engine.adjust_joint(joint_name, axis, 0, 'reset')

        # é‡æ–°æ¸²æŸ“
        image_base64 = engine.render_sequence()

        return jsonify({
            'success': True,
            'image': image_base64,
            'modified': engine.current_frame_idx in engine.adjusted_poses
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/data_info')
def api_data_info():
    """è·å–æ•°æ®é›†ä¿¡æ¯"""
    try:
        return jsonify({
            'success': True,
            'total_frames': engine.total_frames,
            'framerate': engine.framerate,
            'current_sequence': engine.frame_indices
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/sequence_config')
def api_sequence_config():
    """è·å–å½“å‰åºåˆ—é…ç½®å‚æ•°"""
    try:
        return jsonify({
            'success': True,
            'start_frame': engine.start_frame,
            'frame_interval': engine.frame_interval,
            'num_frames': engine.num_frames,
            'frame_offset': engine.frame_offset
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/copy_prev', methods=['POST'])
def api_copy_prev():
    """å¤åˆ¶ä¸Šä¸€å¸§çš„è°ƒèŠ‚å‚æ•°"""
    try:
        copied = engine.copy_prev_frame_adjustments()

        if copied:
            # é‡æ–°æ¸²æŸ“
            image_base64 = engine.render_sequence()

            return jsonify({
                'success': True,
                'image': image_base64,
                'modified': True,
                'message': 'å·²å¤åˆ¶ä¸Šä¸€å¸§å‚æ•°'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•å¤åˆ¶ï¼šå½“å‰ä¸ºç¬¬ä¸€å¸§æˆ–ä¸Šä¸€å¸§æ— è°ƒèŠ‚'
            })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/play_frame', methods=['POST'])
def api_play_frame():
    """æ’­æ”¾æŒ‡å®šå¸§ï¼ˆç”¨äºå¾ªç¯æ’­æ”¾ï¼‰"""
    try:
        data = request.json
        frame_idx = int(data['frame_idx'])

        if 0 <= frame_idx < len(engine.frame_indices):
            frame_image = engine.render_single_frame(frame_idx)

            # è½¬æ¢ä¸ºBase64
            image = Image.fromarray(frame_image)
            buffer = io.BytesIO()
            image.save(buffer, format='PNG')
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')

            return jsonify({
                'success': True,
                'image': f'data:image/png;base64,{image_base64}',
                'frame_idx': frame_idx,
                'frame_count': len(engine.frame_indices),
                'actual_frame': engine.frame_indices[frame_idx]
            })
        else:
            return jsonify({'success': False, 'error': 'å¸§ç´¢å¼•è¶…å‡ºèŒƒå›´'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/update_sequence', methods=['POST'])
def api_update_sequence():
    """æ›´æ–°åºåˆ—å‚æ•°"""
    try:
        data = request.json
        start_frame = int(data['start_frame'])
        frame_interval = int(data['frame_interval'])
        num_frames = int(data['num_frames'])
        frame_offset = int(data.get('frame_offset', 0))

        # éªŒè¯å‚æ•°
        if start_frame < 0 or start_frame >= engine.total_frames:
            return jsonify({'success': False, 'error': f'èµ·å§‹å¸§å¿…é¡»åœ¨0-{engine.total_frames - 1}èŒƒå›´å†…'})

        if frame_interval < 1:
            return jsonify({'success': False, 'error': 'å¸§é—´éš”å¿…é¡»å¤§äº0'})

        if num_frames < 1 or num_frames > 20:
            return jsonify({'success': False, 'error': 'å¸§æ•°å¿…é¡»åœ¨1-20èŒƒå›´å†…'})

        # æ£€æŸ¥åºåˆ—æ˜¯å¦è¶…å‡ºæ•°æ®èŒƒå›´
        max_frame = start_frame + (num_frames - 1) * frame_interval
        if max_frame >= engine.total_frames:
            return jsonify({
                'success': False,
                'error': f'åºåˆ—è¶…å‡ºæ•°æ®èŒƒå›´ï¼Œæœ€å¤§å¸§ä¸º{max_frame}ï¼Œæ•°æ®æ€»å¸§æ•°ä¸º{engine.total_frames}'
            })

        # æ£€æŸ¥å¸§åç§»æ˜¯å¦ä¼šå¯¼è‡´è¶…å‡ºèŒƒå›´
        max_offset_frame = max_frame + abs(frame_offset)
        if max_offset_frame >= engine.total_frames:
            return jsonify({
                'success': False,
                'error': f'å¸§åç§»å¯¼è‡´è¶…å‡ºæ•°æ®èŒƒå›´ï¼Œæœ€å¤§è®¿é—®å¸§ä¸º{max_offset_frame}ï¼Œæ•°æ®æ€»å¸§æ•°ä¸º{engine.total_frames}'
            })

        # æ›´æ–°å¼•æ“é…ç½®
        old_frame_offset = engine.frame_offset
        old_adjusted_poses_count = len(engine.adjusted_poses)

        engine.start_frame = start_frame
        engine.frame_interval = frame_interval
        engine.num_frames = num_frames
        engine.frame_offset = frame_offset
        engine.frame_indices = [start_frame + i * frame_interval for i in range(num_frames)]
        engine.current_frame_idx = 0

        # æ€»æ˜¯æ¸…ç©ºè°ƒèŠ‚æ•°æ®ï¼Œç¡®ä¿å¸§åç§»æ•ˆæœèƒ½å¤Ÿæ˜¾ç°
        engine.adjusted_poses = {}  # æ¸…ç©ºä¹‹å‰çš„è°ƒèŠ‚

        return jsonify({'success': True, 'message': 'å‚æ•°æ›´æ–°æˆåŠŸ'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/current_angles')
def api_current_angles():
    """è·å–å½“å‰å¸§çš„å…³èŠ‚è§’åº¦å€¼ï¼ˆç®€åŒ–ç‰ˆæœ¬ - ç›´æ¥è¿”å›ç»å¯¹è§’åº¦ï¼‰"""
    try:
        # è·å–å½“å‰å§¿æ€ï¼ˆGT + è°ƒèŠ‚ï¼‰
        gt_pose, adjusted_pose = engine.get_current_poses()
        current_pose = adjusted_pose.detach().cpu().numpy().squeeze()

        # è®¡ç®—æ¯ä¸ªå…³èŠ‚çš„ç»å¯¹è§’åº¦å€¼ï¼ˆå¼§åº¦è½¬è§’åº¦ï¼‰
        joint_angles = {}
        for joint_name, config in CORE_JOINTS.items():
            joint_angles[joint_name] = {}
            for axis_idx, pose_idx in enumerate(config['indices']):
                # å½“å‰ç»å¯¹è§’åº¦
                current_angle_radians = current_pose[pose_idx]
                current_angle_degrees = math.degrees(current_angle_radians)
                joint_angles[joint_name][axis_idx] = round(current_angle_degrees, 1)

        return jsonify({
            'success': True,
            'frame_idx': engine.current_frame_idx,
            'actual_frame': engine.frame_indices[engine.current_frame_idx],
            'joint_angles': joint_angles,
            'modified': engine.current_frame_idx in engine.adjusted_poses
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


def initialize_engine():
    """åˆå§‹åŒ–å…¨å±€å¼•æ“å®ä¾‹"""
    global engine
    # åºåˆ—é…ç½®ï¼ˆç”¨æˆ·å¯åŠ¨æ—¶çš„å‚æ•°ï¼‰
    START_FRAME = 40
    TARGET_TIME_INTERVAL_MS = 100  # ç›®æ ‡æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    FRAME_INTERVAL = 20  # æ‰‹åŠ¨å¸§é—´éš”ï¼ˆå¦‚æœä¸ä½¿ç”¨æ—¶é—´é—´éš”ï¼‰
    NUM_FRAMES = 11
    FRAME_OFFSET = 0  # é¢„æµ‹æ•°æ®ç›¸å¯¹äºGTçš„åç§»å¸§æ•°

    # è®¡ç®—å®é™…ä½¿ç”¨çš„å¸§é—´éš”
    if TARGET_TIME_INTERVAL_MS > 0:
        # å¿«é€Ÿè·å–å¸§ç‡ä¿¡æ¯ï¼Œé¿å…é‡å¤åŠ è½½æ•°æ®
        print(f'ğŸ”„ åŠ è½½æ•°æ®é›†: {DATA_SET}')
        data = np.load(DATA_SET)
        try:
            mocap_framerate = float(data['mocap_framerate'])
        except KeyError:
            mocap_framerate = 30.0  # é»˜è®¤å¸§ç‡

        frame_time_ms = 1000.0 / mocap_framerate  # æ¯å¸§æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        calculated_frame_interval = max(1, round(TARGET_TIME_INTERVAL_MS / frame_time_ms))
        actual_time_interval_ms = calculated_frame_interval * frame_time_ms

        print(f'â±ï¸ æ—¶é—´é—´éš”æ§åˆ¶: ç›®æ ‡={TARGET_TIME_INTERVAL_MS}ms, å®é™…={actual_time_interval_ms:.1f}ms')
        print(f'ğŸ“ è‡ªåŠ¨è®¡ç®—å¸§é—´éš”: {calculated_frame_interval} (è¦†ç›–æ‰‹åŠ¨è®¾ç½®={FRAME_INTERVAL})')

        frame_interval_to_use = calculated_frame_interval
    else:
        print(f'ğŸ“ ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®å¸§é—´éš”: {FRAME_INTERVAL}')
        frame_interval_to_use = FRAME_INTERVAL

    # åˆ›å»ºå¼•æ“å®ä¾‹
    engine = PoseAdjusterEngine(START_FRAME, frame_interval_to_use, NUM_FRAMES, FRAME_OFFSET)

    print('ğŸš€ å¯åŠ¨äº¤äº’å¼äººä½“å§¿æ€è°ƒèŠ‚å™¨...')
    print(f'ğŸ“‚ æ•°æ®æ–‡ä»¶: {DATA_SET}')
    print(f'ğŸ¤– æ¨¡å‹æ–‡ä»¶: {SMPL_MODEL}')
    print(f'ğŸ¯ å¸§åºåˆ—: {engine.frame_indices}')
    print(f'âš¡ å¸§åç§»: {FRAME_OFFSET}')
    print('ğŸŒ æœåŠ¡å™¨åœ°å€: http://localhost:5000')
    print('-' * 50)


if __name__ == '__main__':
    initialize_engine()
    app.run(debug=True, host='0.0.0.0', port=5000)
